{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A really really small neural network in numpy for a truth table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEED\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,deriv=False):\n",
    "    \"\"\"\n",
    "    Simple sigmoid activation function using numpy\n",
    "    \"\"\"\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training data\n",
    "These are simple truth tables that we'll learn on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "            [0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([\n",
    "            [0],\n",
    "            [1],\n",
    "            [1],\n",
    "            [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights\n",
    "randomly initialize our weights with mean 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0 = 2*np.random.random((3,4)) - 1\n",
    "w_1 = 2*np.random.random((4,1)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop\n",
    "Recall the steps for performing gradient are:\n",
    "1. Forward pass -> calculate loss\n",
    "2. Backward pass -> calculate gradients\n",
    "3. Update weights\n",
    "4. Repeat to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.498143063951\n",
      "Error: 0.0447576809491\n",
      "Error: 0.0273990949977\n",
      "Error: 0.0212823881636\n",
      "Error: 0.017947679405\n",
      "Error: 0.0157831271653\n",
      "Error: 0.0142368549605\n",
      "Error: 0.0130629438924\n",
      "Error: 0.0121333462089\n",
      "Error: 0.0113740710438\n"
     ]
    }
   ],
   "source": [
    "for j in range(10000):   \n",
    "    # FORWARD PASS through layers 0, 1, and 2\n",
    "    # Note this is just like the perceptrons: activation_function(weighted sum of inputs)\n",
    "    layer_0 = X\n",
    "    layer_1 = sigmoid(np.dot(layer_0,w_0))\n",
    "    layer_2 = sigmoid(np.dot(layer_1,w_1))\n",
    "\n",
    "    # Get loss at the end -> how much did we miss the target value?\n",
    "    Err_layer_2 = y - layer_2\n",
    "    \n",
    "    if (j% 1000) == 0: #every 1000 iterations we'll print error\n",
    "        print(\"Error: {0}\".format(str(np.mean(np.abs(Err_layer_2)))))\n",
    "        \n",
    "    \"\"\"\n",
    "    Now we're perform gradient descent... note this isn't stochastic gradient descent (SGD) b/c we're\n",
    "    not working with mini-batches\n",
    "    \"\"\"\n",
    "    \n",
    "    # BACWARD PASS through layers 2, 1, and 0\n",
    "    # layer_2 delta is just the error * partial derivative\n",
    "    layer_2_delta = Err_layer_2*sigmoid(layer_2,deriv=True)\n",
    "\n",
    "    # Repeat for layer_1: calculate error -> get gradient\n",
    "    Err_layer_1 = layer_2_delta.dot(w_1.T)\n",
    "    layer_1_delta = Err_layer_1 * sigmoid(layer_1,deriv=True)\n",
    "\n",
    "    # WEIGHT UPDATE\n",
    "    w_1 += layer_1.T.dot(layer_2_delta)\n",
    "    w_0 += layer_0.T.dot(layer_1_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
